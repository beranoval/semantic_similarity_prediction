{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6ebf9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random\n",
    "from itertools import chain\n",
    "import embeddings_functions\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import cpu_count\n",
    "from itertools import product\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "811e66cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/yelp\\Dataset_User_Agreement.pdf\n",
      "data/yelp\\yelp_academic_dataset_business.json\n",
      "data/yelp\\yelp_academic_dataset_checkin.json\n",
      "data/yelp\\yelp_academic_dataset_review.json\n",
      "data/yelp\\yelp_academic_dataset_tip.json\n",
      "data/yelp\\yelp_academic_dataset_user.json\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('data/yelp'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        \n",
    "df = pd.read_json(\"data/yelp/yelp_academic_dataset_review.json\", encoding = 'ISO-8859-1', lines=True,nrows=200000)\n",
    "df_proc = df[[\"text\"]].reset_index()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[\\W\\d_]', ' ', text)  \n",
    "    text = text.lower()  \n",
    "    return text\n",
    "\n",
    "df_proc['text'] = df_proc['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "386bd674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "319465e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc['language'] = df_proc['text'].apply(lambda x: detect(x))\n",
    "df_proc = df_proc[df_proc['language'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beee1c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199781"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7c4b44",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da3711dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_proc = pd.DataFrame({'text': [\n",
    "#    \"apple pie\",\n",
    "#    \"she bought banana\",\n",
    "#    \"he drinks orange juice\",\n",
    "#    \"test1 test2\",\n",
    "#    \"test1 test3\",  \n",
    "#]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dc7e424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>text_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>if you decide to eat here  just be aware it is...</td>\n",
       "      <td>en</td>\n",
       "      <td>[if, you, decide, to, eat, here, just, be, awa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>i ve taken a lot of spin classes over the year...</td>\n",
       "      <td>en</td>\n",
       "      <td>[i, ve, taken, a, lot, of, spin, classes, over...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>family diner  had the buffet  eclectic assortm...</td>\n",
       "      <td>en</td>\n",
       "      <td>[family, diner, had, the, buffet, eclectic, as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>wow   yummy  different   delicious    our favo...</td>\n",
       "      <td>en</td>\n",
       "      <td>[wow, yummy, different, delicious, our, favori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cute interior and owner     gave us tour of up...</td>\n",
       "      <td>en</td>\n",
       "      <td>[cute, interior, and, owner, gave, us, tour, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>199995</td>\n",
       "      <td>oakley s bistro is a hidden gem for indianapol...</td>\n",
       "      <td>en</td>\n",
       "      <td>[oakley, s, bistro, is, a, hidden, gem, for, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>199996</td>\n",
       "      <td>let me just say  i m glad my husband and i dec...</td>\n",
       "      <td>en</td>\n",
       "      <td>[let, me, just, say, i, m, glad, my, husband, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>199997</td>\n",
       "      <td>i was coming back from the farmers market toda...</td>\n",
       "      <td>en</td>\n",
       "      <td>[i, was, coming, back, from, the, farmers, mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>199998</td>\n",
       "      <td>absolutely perfect meal for me  the food is cl...</td>\n",
       "      <td>en</td>\n",
       "      <td>[absolutely, perfect, meal, for, me, the, food...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>199999</td>\n",
       "      <td>braised beef short rib  asparagus on the side ...</td>\n",
       "      <td>en</td>\n",
       "      <td>[braised, beef, short, rib, asparagus, on, the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199781 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                               text language  \\\n",
       "0            0  if you decide to eat here  just be aware it is...       en   \n",
       "1            1  i ve taken a lot of spin classes over the year...       en   \n",
       "2            2  family diner  had the buffet  eclectic assortm...       en   \n",
       "3            3  wow   yummy  different   delicious    our favo...       en   \n",
       "4            4  cute interior and owner     gave us tour of up...       en   \n",
       "...        ...                                                ...      ...   \n",
       "199995  199995  oakley s bistro is a hidden gem for indianapol...       en   \n",
       "199996  199996  let me just say  i m glad my husband and i dec...       en   \n",
       "199997  199997  i was coming back from the farmers market toda...       en   \n",
       "199998  199998  absolutely perfect meal for me  the food is cl...       en   \n",
       "199999  199999  braised beef short rib  asparagus on the side ...       en   \n",
       "\n",
       "                                                 text_tok  \n",
       "0       [if, you, decide, to, eat, here, just, be, awa...  \n",
       "1       [i, ve, taken, a, lot, of, spin, classes, over...  \n",
       "2       [family, diner, had, the, buffet, eclectic, as...  \n",
       "3       [wow, yummy, different, delicious, our, favori...  \n",
       "4       [cute, interior, and, owner, gave, us, tour, o...  \n",
       "...                                                   ...  \n",
       "199995  [oakley, s, bistro, is, a, hidden, gem, for, i...  \n",
       "199996  [let, me, just, say, i, m, glad, my, husband, ...  \n",
       "199997  [i, was, coming, back, from, the, farmers, mar...  \n",
       "199998  [absolutely, perfect, meal, for, me, the, food...  \n",
       "199999  [braised, beef, short, rib, asparagus, on, the...  \n",
       "\n",
       "[199781 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proc['text_tok'] = df_proc['text'].apply(word_tokenize)\n",
    "df_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b515dc98",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c13e956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n"
     ]
    }
   ],
   "source": [
    "model_name = \"second\"\n",
    "word_embeddings = embeddings_functions.Word2VecEmbeddings(df_proc['text_tok'].tolist(),model_name)\n",
    "word_embeddings.train_model(window = 3,min_count = 1, seed = 1,sg = 1,vector_size=100,norm = True, sample = None,epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8337105d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20511799\n"
     ]
    }
   ],
   "source": [
    "flattened_list = list(chain(*df_proc['text_tok'].tolist()))\n",
    "print(len(flattened_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1969d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_list_s = random.sample(flattened_list, 10000)\n",
    "embeddings = word_embeddings.get_embeddings(words = flattened_list_s)\n",
    "similarity = embeddings_functions.Similarity2(embeddings_df = embeddings)\n",
    "df_cosine = similarity.get_cosine_similarity_of_all_words2().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "431247c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>First</th>\n",
       "      <th>Last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300317</td>\n",
       "      <td>type</td>\n",
       "      <td>when</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.395349</td>\n",
       "      <td>type</td>\n",
       "      <td>would</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.253379</td>\n",
       "      <td>type</td>\n",
       "      <td>followed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.204571</td>\n",
       "      <td>type</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.265206</td>\n",
       "      <td>type</td>\n",
       "      <td>always</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503198</th>\n",
       "      <td>0.421382</td>\n",
       "      <td>recipe</td>\n",
       "      <td>saki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503199</th>\n",
       "      <td>0.238683</td>\n",
       "      <td>recipe</td>\n",
       "      <td>intimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503200</th>\n",
       "      <td>0.318745</td>\n",
       "      <td>clayton</td>\n",
       "      <td>saki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503201</th>\n",
       "      <td>0.334505</td>\n",
       "      <td>clayton</td>\n",
       "      <td>intimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503202</th>\n",
       "      <td>0.262342</td>\n",
       "      <td>saki</td>\n",
       "      <td>intimate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2503203 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         similarity    First      Last\n",
       "0          0.300317     type      when\n",
       "1          0.395349     type     would\n",
       "2          0.253379     type  followed\n",
       "3          0.204571     type       she\n",
       "4          0.265206     type    always\n",
       "...             ...      ...       ...\n",
       "2503198    0.421382   recipe      saki\n",
       "2503199    0.238683   recipe  intimate\n",
       "2503200    0.318745  clayton      saki\n",
       "2503201    0.334505  clayton  intimate\n",
       "2503202    0.262342     saki  intimate\n",
       "\n",
       "[2503203 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1ddec96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAncAAAF3CAYAAADHIm3/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAl0ElEQVR4nO3df7RVdZ3/8edbMFFCxZ8p6MCY3xJQRK6omSYyJZmmrtGiZpIKpcyZGvuuZrRmJdN8XSv7+s2yvtZolj9GU/xRMq2xCX/nN1MhEX+QSWp6B1L8kWIlAb6/f5x96XA5wOFyzz33fng+1jrr7vPZ+7PP+2xd97747P3ZOzITSZIklWGrdhcgSZKk3mO4kyRJKojhTpIkqSCGO0mSpIIY7iRJkgpiuJMkSSpIy8JdRHw3Ip6PiEfq2v53RPwyIhZGxA8iYse6dedExOKIeDwijqlrnxgRD1frLoqIqNq3iYjrqvb7ImJUXZ/pEfFE9Zrequ8oSZLU37Ry5O5yYGq3trnAuMw8APgVcA5ARIwBpgFjqz4XR8Sgqs+3gJnAvtWra58zgJcz863AhcD51b52As4FDgEmAedGxPAWfD9JkqR+p2XhLjPvBl7q1vaTzFxVvf05MLJaPgG4NjNXZOZTwGJgUkTsAWyfmfdm7W7LVwIn1vW5olq+AZhSjeodA8zNzJcy82VqgbJ7yJQkSSpSO6+5+zhwS7U8Ani2bl1n1TaiWu7evlafKjC+Auy8gX1JkiQVb3A7PjQivgCsAq7uamqwWW6gvad9utcxk9opX4YOHTrx7W9/+waqliRJ6h/mz5//Qmbu2mhdn4e7aoLDccCU/PODbTuBveo2GwksqdpHNmiv79MZEYOBHaidBu4EjurW585GtWTmJcAlAB0dHTlv3ryefi1JkqQ+ExG/Wd+6Pj0tGxFTgX8C3p+Zf6hbNQeYVs2AHU1t4sT9mbkUWB4Rh1bX050K3FzXp2sm7MnA7VVY/C/gPRExvJpI8Z6qTZIkqXgtG7mLiO9TG0HbJSI6qc1gPQfYBphb3dHk55n5ycx8NCJmA49RO117ZmaurnZ1BrWZt9tSu0av6zq9y4CrImIxtRG7aQCZ+VJE/CvwQLXdlzJzrYkdkiRJpYo/nxndsnlaVpIkDRQRMT8zOxqta8uECkmS1HtWrlxJZ2cnr7/+ertLUS8bMmQII0eOZOutt266j+FOkqQBrrOzk2HDhjFq1Ciqy55UgMzkxRdfpLOzk9GjRzfdz2fLSpI0wL3++uvsvPPOBrvCRAQ777zzJo/IGu4kSSqAwa5MPfnvariTJEmb7be//S3Tpk1jn332YcyYMRx77LH86le/2uT9HHvssfzud7/b7Hqee+45jjvuOMaPH7+mHoAlS5Zw8sknb9K+vvjFL3LrrbcCcNRRR7GpEzDr+3/ta1/jD3/4w0Z6bB5ny1acLStJGqgWLVrEfvvtt+b9rFm9u/+N7S8zecc73sH06dP55Cc/CcCCBQtYvnw5RxxxRO8W06RPfOITjBkzhs985jMALFy4kAMOOGCz93vUUUdxwQUX0NHRcKLqOlavXs2gQYPWvB81ahTz5s1jl112afozu//3hQ3PlnXkTpIkbZY77riDrbfeek2wAzjwwAM54ogjyEw+97nPMW7cOPbff3+uu+46AJYuXcqRRx7JgQceyLhx4/jpT38K1MLPCy+8wNNPP81+++3H6aefztixY3nPe97DH//4RwB+/etfM3XqVCZOnMgRRxzBL3/5y3VqWrp0KSNH/vkhV13B7umnn2bcuHEAXH755Zx44okcf/zxjB49mm9+85t89atfZcKECRx66KG89FLtNrkf/ehHueGGG9b5jDPOOIOOjg7Gjh3Lueeeu6Z91KhRfOlLX+Kd73wn119//Zr+F110EUuWLGHy5MlMnjyZyy67jLPOOmtNv0svvZTPfvazPfuPUMdwJ0mSNssjjzzCxIkTG6676aabWLBgAQ899BC33norn/vc51i6dCnXXHMNxxxzzJp1Bx544Dp9n3jiCc4880weffRRdtxxR2688UYAZs6cyTe+8Q3mz5/PBRdcwKc+9al1+p555pnMmDGDyZMnc95557FkyZJ1tumq/ZprruH+++/nC1/4Attttx0PPvgghx12GFdeeeUGv/d5553HvHnzWLhwIXfddRcLFy5cs27IkCHcc889TJs2bU3bpz/9afbcc0/uuOMO7rjjDqZNm8acOXNYuXIlAN/73vf42Mc+tsHPbIa3QpEkSS1zzz338KEPfYhBgwax++678653vYsHHniAgw8+mI9//OOsXLmSE088sWG4Gz169Jr2iRMn8vTTT/Paa6/xs5/9jFNOOWXNditWrFin7zHHHMOTTz7Jj3/8Y2655RYmTJjAI488ss52kydPZtiwYQwbNowddtiB448/HoD9999/rbDWyOzZs7nkkktYtWoVS5cu5bHHHlszQvjBD35wo8dm6NChHH300fzoRz9iv/32Y+XKley///4b7bcxjtxJkqTNMnbsWObPn99w3fqu7T/yyCO5++67GTFiBB/5yEcajpJts802a5YHDRrEqlWreOONN9hxxx1ZsGDBmteiRYsafsZOO+3Ehz/8Ya666ioOPvhg7r777g1+xlZbbbXm/VZbbcWqVavW+52feuopLrjgAm677TYWLlzI+973vrVuWTJ06ND19q132mmncfnll/faqB0Y7iT1U7NmrfuS1D8dffTRrFixgksvvXRN2wMPPMBdd93FkUceyXXXXcfq1atZtmwZd999N5MmTeI3v/kNu+22G6effjozZszgF7/4RVOftf322zN69Giuv/56oBYeH3rooXW2u/3229fMSl2+fDm//vWv2XvvvXvh29a8+uqrDB06lB122IHnnnuOW265pal+w4YNY/ny5WveH3LIITz77LNcc801fOhDH+qV2gx3kiRps0QEP/jBD5g7dy777LMPY8eOZdasWey5556cdNJJHHDAAYwfP56jjz6ar3zlK7zlLW/hzjvv5MADD2TChAnceOONa2a1NuPqq6/msssuY/z48YwdO5abb755nW3mz59PR0cHBxxwAIcddhinnXYaBx98cK995/HjxzNhwgTGjh3Lxz/+cQ4//PCm+s2cOZP3vve9TJ48eU3bBz7wAQ4//HCGDx/eK7V5K5SKt0KR+pdGI3WO3kmNNbpVhgaO4447jrPOOospU6Y0XL+pt0JxQoWkAcPAJ6kkv/vd75g0aRLjx49fb7DrCcOdJElSG+y44449eorHxhjuJLWdo2+S1HucUCFJUgG8hr5MPfnvariTJGmAGzJkCC+++KIBrzCZyYsvvsiQIUM2qZ+nZSVJGuBGjhxJZ2cny5Yta3cp6mVDhgxZ6xm5zTDcSRrQnEErwdZbb83o0aPbXYb6CU/LSpIkFcRwJ0mSVBBPy0rqU54ylaTWcuROkiSpIIY7SZKkghjuJEmSCuI1d5KK4+1RJG3JHLmTJEkqiOFOkiSpIIY7SZKkghjuJEmSCmK4kyRJKojhTpIkqSDeCkVSy3j7EUnqe47cSZIkFcRwJ0mSVBDDnSRJUkEMd5IkSQUx3EmSJBXE2bKStgiNZu46m1dSiRy5kyRJKojhTpIkqSCGO0mSpIIY7iRJkgpiuJMkSSpIy8JdRHw3Ip6PiEfq2naKiLkR8UT1c3jdunMiYnFEPB4Rx9S1T4yIh6t1F0VEVO3bRMR1Vft9ETGqrs/06jOeiIjprfqOkiRJ/U0rR+4uB6Z2azsbuC0z9wVuq94TEWOAacDYqs/FETGo6vMtYCawb/Xq2ucM4OXMfCtwIXB+ta+dgHOBQ4BJwLn1IVKSJKlkLQt3mXk38FK35hOAK6rlK4AT69qvzcwVmfkUsBiYFBF7ANtn5r2ZmcCV3fp07esGYEo1qncMMDczX8rMl4G5rBsyJUmSitTXNzHePTOXAmTm0ojYrWofAfy8brvOqm1ltdy9vavPs9W+VkXEK8DO9e0N+khqAW8GLEn9R3+ZUBEN2nID7T3ts/aHRsyMiHkRMW/ZsmVNFSpJktSf9XW4e6461Ur18/mqvRPYq267kcCSqn1kg/a1+kTEYGAHaqeB17evdWTmJZnZkZkdu+6662Z8LUmSpP6hr8PdHKBr9up04Oa69mnVDNjR1CZO3F+dwl0eEYdW19Od2q1P175OBm6vrsv7L+A9ETG8mkjxnqpNkiSpeC275i4ivg8cBewSEZ3UZrB+GZgdETOAZ4BTADLz0YiYDTwGrALOzMzV1a7OoDbzdlvgluoFcBlwVUQspjZiN63a10sR8a/AA9V2X8rM7hM7JEmSitSycJeZH1rPqinr2f484LwG7fOAcQ3aX6cKhw3WfRf4btPFSpIkFaKvZ8tKUr/RaJavM38lDXT9ZbasJEmSeoHhTpIkqSCGO0mSpIIY7iRJkgpiuJMkSSqI4U6SJKkghjtJkqSCGO4kSZIKYriTJEkqiOFOkiSpIIY7SZKkghjuJEmSCmK4kyRJKsjgdhcgaWCZNavdFUiSNsSRO0mSpII4cidJdRqNTDpaKWkgceROkiSpIIY7SZKkghjuJEmSCmK4kyRJKojhTpIkqSCGO0mSpIIY7iRJkgpiuJMkSSqI4U6SJKkghjtJkqSCGO4kSZIKYriTJEkqiOFOkiSpIIY7SZKkghjuJEmSCmK4kyRJKojhTpIkqSCGO0mSpIIMbncBktTfzZrVXJsk9QeGO0nrZYCRpIHH07KSJEkFMdxJkiQVxHAnSZJUEMOdJElSQQx3kiRJBTHcSZIkFcRwJ0mSVBDDnSRJUkEMd5IkSQVpS7iLiLMi4tGIeCQivh8RQyJip4iYGxFPVD+H121/TkQsjojHI+KYuvaJEfFwte6iiIiqfZuIuK5qvy8iRrXha0qSJPW5Pg93ETEC+DTQkZnjgEHANOBs4LbM3Be4rXpPRIyp1o8FpgIXR8SganffAmYC+1avqVX7DODlzHwrcCFwfh98NUmSpLZr12nZwcC2ETEY2A5YApwAXFGtvwI4sVo+Abg2M1dk5lPAYmBSROwBbJ+Z92ZmAld269O1rxuAKV2jepIkSSXr83CXmf8NXAA8AywFXsnMnwC7Z+bSapulwG5VlxHAs3W76KzaRlTL3dvX6pOZq4BXgJ1b8X0kSZL6k3aclh1ObWRtNLAnMDQi/nZDXRq05QbaN9Sney0zI2JeRMxbtmzZhguXJEkaANpxWvavgKcyc1lmrgRuAt4BPFedaqX6+Xy1fSewV13/kdRO43ZWy93b1+pTnfrdAXipeyGZeUlmdmRmx6677tpLX0+SJKl92hHungEOjYjtquvgpgCLgDnA9Gqb6cDN1fIcYFo1A3Y0tYkT91enbpdHxKHVfk7t1qdrXycDt1fX5UmSJBVtcF9/YGbeFxE3AL8AVgEPApcAbwZmR8QMagHwlGr7RyNiNvBYtf2Zmbm62t0ZwOXAtsAt1QvgMuCqiFhMbcRuWh98NUmSpLYLB7RqOjo6ct68ee0uQ+pXZs1qdwUDi8dLUl+JiPmZ2dFonU+okCRJKojhTpIkqSCGO0mSpIIY7iRJkgpiuJMkSSpIn98KRVL/5ExPSSqDI3eSJEkFMdxJkiQVxHAnSZJUEMOdJElSQQx3kiRJBTHcSZIkFcRwJ0mSVBDDnSRJUkEMd5IkSQUx3EmSJBXEcCdJklQQw50kSVJBBre7AEkqxaxZzbVJUis5cidJklQQw50kSVJBDHeSJEkFMdxJkiQVxHAnSZJUEMOdJElSQZoKdxExrtWFSJIkafM1O3L37Yi4PyI+FRE7trIgSZIk9VxT4S4z3wn8DbAXMC8iromId7e0MkmSJG2ypp9QkZlPRMQ/A/OAi4AJERHA5zPzplYVKKn3+dQESSpXs9fcHRARFwKLgKOB4zNzv2r5whbWJ0mSpE3Q7MjdN4FLqY3S/bGrMTOXVKN5kiRJ6geaDXfHAn/MzNUAEbEVMCQz/5CZV7WsOkmSJG2SZmfL3gpsW/d+u6pNkiRJ/Uiz4W5IZr7W9aZa3q41JUmSJKmnmg13v4+Ig7reRMRE4I8b2F6SJElt0Ow1d/8AXB8RS6r3ewAfbElFkiRJ6rGmwl1mPhARbwfeBgTwy8xc2dLKJEmStMmavokxcDAwquozISLIzCtbUpUkSZJ6pKlwFxFXAfsAC4DVVXMChjtJ2oD1PQ3Ep4RIapVmR+46gDGZma0sRpIkSZun2dmyjwBvaWUhkiRJ2nzNjtztAjwWEfcDK7oaM/P9LalKkiRJPdJsuJvVyiIkSZLUO5q9FcpdEfEXwL6ZeWtEbAcMam1pkiRJ2lRNXXMXEacDNwD/VjWNAH7YopokSZLUQ81OqDgTOBx4FSAznwB26+mHRsSOEXFDRPwyIhZFxGERsVNEzI2IJ6qfw+u2PyciFkfE4xFxTF37xIh4uFp3UURE1b5NRFxXtd8XEaN6WqskSdJA0my4W5GZf+p6ExGDqd3nrqe+Dvw4M98OjAcWAWcDt2XmvsBt1XsiYgwwDRgLTAUujoiuU8LfAmYC+1avqVX7DODlzHwrcCFw/mbUKkmSNGA0G+7uiojPA9tGxLuB64H/6MkHRsT2wJHAZQCZ+afM/B1wAnBFtdkVwInV8gnAtZm5IjOfAhYDkyJiD2D7zLy3uv/eld36dO3rBmBK16ieJElSyZoNd2cDy4CHgU8A/wn8cw8/8y+rfX0vIh6MiO9ExFBg98xcClD97DrtOwJ4tq5/Z9U2olru3r5Wn8xcBbwC7NzDeiVJkgaMZmfLvgFcWr164zMPAv4+M++LiK9TnYJdj0YjbrmB9g31WXvHETOpndZl77333lDNkiRJA0Kzs2Wfiognu796+JmdQGdm3le9v4Fa2HuuOtVK9fP5uu33qus/ElhStY9s0L5Wn+r6wB2Al7oXkpmXZGZHZnbsuuuuPfw6kiRJ/cemPFu2yxDgFGCnnnxgZv42Ip6NiLdl5uPAFOCx6jUd+HL18+aqyxzgmoj4KrAntYkT92fm6ohYHhGHAvcBpwLfqOszHbgXOBm43efiakvlA+olacvS7GnZF7s1fS0i7gG+2MPP/Xvg6oh4E/Ak8DFqo4izI2IG8Ay1AElmPhoRs6mFv1XAmZm5utrPGcDlwLbALdULapM1roqIxdRG7Kb1sE5JkqQBpalwFxEH1b3ditpI3rCefmhmLmDt0cAuU9az/XnAeQ3a5wHjGrS/ThUOJUmStiTNnpb9P3XLq4CngQ/0ejWSJEnaLM2elp3c6kIkSZK0+Zo9LfvZDa3PzK/2TjmSJEnaHJsyW/ZgarNQAY4H7mbtmwtLkprUaBazM5sl9YZmw90uwEGZuRwgImYB12fmaa0qTJIkSZuu2ceP7Q38qe79n4BRvV6NJEmSNkuzI3dXAfdHxA+oPcbrJODKllUlSZKkHml2tux5EXELcETV9LHMfLB1ZUmSJKknmj0tC7Ad8Gpmfh3ojIjRLapJkiRJPdRUuIuIc4F/As6pmrYG/r1VRUmSJKlnmh25Owl4P/B7gMxcwmY8fkySJEmt0Wy4+1NmJrXJFETE0NaVJEmSpJ5qNtzNjoh/A3aMiNOBW4FLW1eWJEmSemKjs2UjIoDrgLcDrwJvA76YmXNbXJskSZI20UbDXWZmRPwwMycCBjpJkqR+rNnTsj+PiINbWokkSZI2W7NPqJgMfDIinqY2YzaoDeod0KrCJEmStOk2GO4iYu/MfAZ4bx/VI0mSpM2wsZG7HwIHZeZvIuLGzPzrPqhJkiRJPbSxa+6ibvkvW1mIJEmSNt/GRu5yPcuS+qFZs9pdgSSp3TYW7sZHxKvURvC2rZbhzxMqtm9pdZIkSdokGwx3mTmorwqRpC1do5FXR2Mlbapm73MnSZKkAcBwJ0mSVBDDnSRJUkEMd5IkSQUx3EmSJBXEcCdJklQQw50kSVJBDHeSJEkFMdxJkiQVxHAnSZJUEMOdJElSQQx3kiRJBTHcSZIkFcRwJ0mSVBDDnSRJUkEMd5IkSQUZ3O4CJEnrN2tWc22S1MWRO0mSpIIY7iRJkgpiuJMkSSqI19xJA5TXXUmSGnHkTpIkqSBtC3cRMSgiHoyIH1Xvd4qIuRHxRPVzeN2250TE4oh4PCKOqWufGBEPV+suioio2reJiOuq9vsiYlSff0FJkqQ2aOfI3WeARXXvzwZuy8x9gduq90TEGGAaMBaYClwcEYOqPt8CZgL7Vq+pVfsM4OXMfCtwIXB+a7+KJElS/9CWcBcRI4H3Ad+paz4BuKJavgI4sa792sxckZlPAYuBSRGxB7B9Zt6bmQlc2a1P175uAKZ0jepJkiSVrF0jd18D/hF4o65t98xcClD93K1qHwE8W7ddZ9U2olru3r5Wn8xcBbwC7Nyr30CSJKkf6vNwFxHHAc9n5vxmuzRoyw20b6hP91pmRsS8iJi3bNmyJsuRJEnqv9oxcnc48P6IeBq4Fjg6Iv4deK461Ur18/lq+05gr7r+I4ElVfvIBu1r9YmIwcAOwEvdC8nMSzKzIzM7dt111975dpIkSW3U5+EuM8/JzJGZOYraRInbM/NvgTnA9Gqz6cDN1fIcYFo1A3Y0tYkT91enbpdHxKHV9XSnduvTta+Tq89YZ+ROkiSpNP3pJsZfBmZHxAzgGeAUgMx8NCJmA48Bq4AzM3N11ecM4HJgW+CW6gVwGXBVRCymNmI3ra++hCRJUju1Ndxl5p3AndXyi8CU9Wx3HnBeg/Z5wLgG7a9ThUNJkqQtSX8auZMkNaHRo+d8HJ2kLj5+TJIkqSCGO0mSpIIY7iRJkgpiuJMkSSqI4U6SJKkghjtJkqSCeCsUaQDwNheSpGY5cidJklQQw50kSVJBDHeSJEkFMdxJkiQVxHAnSZJUEMOdJElSQbwViiQVoNHtcryFjrRlcuROkiSpIIY7SZKkghjuJEmSCmK4kyRJKojhTpIkqSCGO0mSpIIY7iRJkgpiuJMkSSqI4U6SJKkghjtJkqSC+PgxqZ/xkVGSpM3hyJ0kSVJBDHeSJEkF8bSsJBWq0Sl+T/tL5XPkTpIkqSCGO0mSpIIY7iRJkgpiuJMkSSqI4U6SJKkghjtJkqSCGO4kSZIKYriTJEkqiOFOkiSpIIY7SZKkghjuJEmSCuKzZaU28jmfkqTeZriTpC1Io39Q+I8MqSyelpUkSSqI4U6SJKkghjtJkqSCGO4kSZIK0ufhLiL2iog7ImJRRDwaEZ+p2neKiLkR8UT1c3hdn3MiYnFEPB4Rx9S1T4yIh6t1F0VEVO3bRMR1Vft9ETGqr7+nJElSO7Rj5G4V8D8zcz/gUODMiBgDnA3clpn7ArdV76nWTQPGAlOBiyNiULWvbwEzgX2r19SqfQbwcma+FbgQOL8vvpgkSVK79Xm4y8ylmfmLank5sAgYAZwAXFFtdgVwYrV8AnBtZq7IzKeAxcCkiNgD2D4z783MBK7s1qdrXzcAU7pG9SRJkkrW1mvuqtOlE4D7gN0zcynUAiCwW7XZCODZum6dVduIarl7+1p9MnMV8Aqwc0u+hCRJUj/StnAXEW8GbgT+ITNf3dCmDdpyA+0b6tO9hpkRMS8i5i1btmxjJUuSJPV7bXlCRURsTS3YXZ2ZN1XNz0XEHpm5tDrl+nzV3gnsVdd9JLCkah/ZoL2+T2dEDAZ2AF7qXkdmXgJcAtDR0bFO+JOkLYFPrZDK0o7ZsgFcBizKzK/WrZoDTK+WpwM317VPq2bAjqY2ceL+6tTt8og4tNrnqd36dO3rZOD26ro8SZKkorVj5O5w4CPAwxGxoGr7PPBlYHZEzACeAU4ByMxHI2I28Bi1mbZnZubqqt8ZwOXAtsAt1Qtq4fGqiFhMbcRuWou/k7RRjoRIkvpCn4e7zLyHxtfEAUxZT5/zgPMatM8DxjVof50qHEqSJG1JfEKFJElSQQx3kiRJBTHcSZIkFcRwJ0mSVBDDnSRJUkHachNjSVL/5o2NpYHLkTtJkqSCGO4kSZIKYriTJEkqiNfcSS3gtUmSpHZx5E6SJKkghjtJkqSCeFpWktQUb48iDQyO3EmSJBXEcCdJklQQw50kSVJBDHeSJEkFMdxJkiQVxNmy0mZwpqC2dM6glfofR+4kSZIKYriTJEkqiOFOkiSpIIY7SZKkgjihQpLUq5xkIbWXI3eSJEkFMdxJkiQVxNOyUpM8rSRJGggMd5KklvM6PKnveFpWkiSpIIY7SZKkghjuJEmSCuI1d5KktljfNXdeiydtHsOd1IB/XCRJA5WnZSVJkgriyJ0kqV/xtinS5nHkTpIkqSCO3GmL54iA1P85mic1z5E7SZKkgjhyJ0kakBzNkxpz5E6SJKkgjtxpi+K/6qWyOZonGe4kSYUz8GlL42lZSZKkgjhyp2L5L3NJ69Ps7wd/j2ggMtypCP4CltQKntLVQFR0uIuIqcDXgUHAdzLzy20uSZI0wBn41N8VG+4iYhDwf4F3A53AAxExJzMfa29l2lz+EpXU32zO7yV/p6m3FRvugEnA4sx8EiAirgVOAAx3A4i/9CSVrq9+z/n7dMtRcrgbATxb974TOKRNtWwx/OUhSf1TSb+fS/ourVByuIsGbbnWBhEzgZnV29ci4vEm970L8MJm1KYN8/i2nse4tTy+reXxbb1+fYz/5V/aXcFm643j+xfrW1FyuOsE9qp7PxJYUr9BZl4CXLKpO46IeZnZsXnlaX08vq3nMW4tj29reXxbz2PcWq0+viXfxPgBYN+IGB0RbwKmAXPaXJMkSVJLFTtyl5mrIuLvgP+idiuU72bmo20uS5IkqaWKDXcAmfmfwH+2YNebfCpXm8Tj23oe49by+LaWx7f1PMat1dLjG5m58a0kSZI0IJR8zZ0kSdIWx3DXhIjYKSLmRsQT1c/hDbbZKyLuiIhFEfFoRHymHbUOJBExNSIej4jFEXF2g/URERdV6xdGxEHtqHOgauL4/k11XBdGxM8iYnw76hzINnaM67Y7OCJWR8TJfVnfQNfM8Y2IoyJiQfV7966+rnEga+J3xA4R8R8R8VB1fD/WjjoHqoj4bkQ8HxGPrGd96/7GZaavjbyArwBnV8tnA+c32GYP4KBqeRjwK2BMu2vvry9qk1x+Dfwl8Cbgoe7HCzgWuIXaPQsPBe5rd90D5dXk8X0HMLxafq/Ht/ePcd12t1O7/vfkdtc9UF5N/j+8I7WnDu1dvd+t3XUPlFeTx/fzXX/vgF2Bl4A3tbv2gfICjgQOAh5Zz/qW/Y1z5K45JwBXVMtXACd23yAzl2bmL6rl5cAiak/JUGNrHg+XmX8Cuh4PV+8E4Mqs+TmwY0Ts0deFDlAbPb6Z+bPMfLl6+3Nq94JU85r5fxjg74Ebgef7srgCNHN8PwzclJnPAGSmx7h5zRzfBIZFRABvphbuVvVtmQNXZt5N7ZitT8v+xhnumrN7Zi6FWogDdtvQxhExCpgA3Nf60gasRo+H6x6Gm9lGjW3qsZtB7V+Qat5Gj3FEjABOAr7dh3WVopn/h/8HMDwi7oyI+RFxap9VN/A1c3y/CexH7QEADwOfycw3+qa8LULL/sYVfSuUTRERtwJvabDqC5u4nzdT+1f6P2Tmq71RW6E2+ni4JrdRY00fu4iYTC3cvbOlFZWnmWP8NeCfMnN1bfBDm6CZ4zsYmAhMAbYF7o2In2fmr1pdXAGaOb7HAAuAo4F9gLkR8VP/tvWalv2NM9xVMvOv1rcuIp6LiD0yc2k1ZNpw6D8itqYW7K7OzJtaVGopNvp4uCa3UWNNHbuIOAD4DvDezHyxj2orRTPHuAO4tgp2uwDHRsSqzPxhn1Q4sDX7O+KFzPw98PuIuBsYT+2aZ21YM8f3Y8CXs3aB2OKIeAp4O3B/35RYvJb9jfO0bHPmANOr5enAzd03qK5JuAxYlJlf7cPaBqpmHg83Bzi1mlF0KPBK1+lxbdRGj29E7A3cBHzEkY4e2egxzszRmTkqM0cBNwCfMtg1rZnfETcDR0TE4IjYDjiE2vXO2rhmju8z1EZFiYjdgbcBT/ZplWVr2d84R+6a82VgdkTMoPY/+ykAEbEn8J3MPBY4HPgI8HBELKj6fT5rT8lQN7mex8NFxCer9d+mNrvwWGAx8Adq/4pUE5o8vl8EdgYurkaWVqUPCm9ak8dYPdTM8c3MRRHxY2Ah8Aa138cNbzuhtTX5/++/ApdHxMPUTiH+U2a+0LaiB5iI+D5wFLBLRHQC5wJbQ+v/xvmECkmSpIJ4WlaSJKkghjtJkqSCGO4kSZIKYriTJEkqiOFOkiSpIIY7SQIi4gsR8WhELIyIBRFxSER8JyLGbMI+OiLiomr5oxHxzU2sob7/URHxjk37FpLkfe4kiYg4DDgOOCgzV0TELsCbMvO0TdlPZs4D5vWwhsHd+h8FvAb8rCf7k7TlcuROkmAPao+xWgGQmS9k5pLqgfQdABHxWkScXz2g/taImFStfzIi3l9tc1RE/Kj7ziPi+Ii4LyIerPruXrXPiohLIuInwJVd/SNiFPBJ4KxqFPGIiHiqesQhEbF9RDzd9V6S6hnuJAl+AuwVEb+KiIsj4l0NthkK3JmZE4HlwP8C3g2cBHxpI/u/Bzg0MycA1wL/WLduInBCZn64qyEznwa+DVyYmQdm5k+BO4H3VZtMA27MzJWb9jUlbQk8LStpi5eZr0XEROAIYDJwXUSc3W2zPwE/rpYfBlZk5srq0UyjNvIRI6t97gG8CXiqbt2czPxjE2V+h1oo/CG1xxSd3kQfSVsgR+4kCcjM1Zl5Z2aeC/wd8NfdNlmZf35e4xtA1yncN9j4P5S/AXwzM/cHPgEMqVv3+ybr+3/AqGpUcZDPUJW0PoY7SVu8iHhbROxb13Qg8Jte/IgdgP+ulqc32Wc5MKxb25XA94Hv9VJdkgpkuJMkeDNwRUQ8FhELgTHArF7c/yzg+oj4KfBCk33+Azipa0JF1XY1MJxawJOkhuLPZxkkSf1ZRJxMbfLFR9pdi6T+ywkVkjQARMQ3gPcCx7a7Fkn9myN3kiRJBfGaO0mSpIIY7iRJkgpiuJMkSSqI4U6SJKkghjtJkqSCGO4kSZIK8v8BnExLNZ4ofBwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_cosine[\"similarity\"], bins=100, color=\"blue\", alpha=0.5, label=\"Cosine Similarity\")\n",
    "plt.xlabel(\"Similarity\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc0d7c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_occurrence_corr(sentences, window_size):\n",
    "    \n",
    "    d = defaultdict(int)\n",
    "    vocab = set()\n",
    "    \n",
    "    # Vytvoření slovníku četností slov\n",
    "    for text in tqdm.tqdm(sentences):\n",
    "        for i in range(len(text)):\n",
    "            token = text[i]\n",
    "            vocab.add(token)  # add to vocab\n",
    "            next_tokens = text[i+1 : i+1+window_size]\n",
    "            for next_token in next_tokens:\n",
    "                key = tuple(sorted([next_token, token]))\n",
    "                d[key] += 1\n",
    "                \n",
    "    # Vytvoření matice frekvencí\n",
    "    vocab = sorted(vocab) # Seřazení slovníku\n",
    "    vocab_index = {word: i for i, word in enumerate(vocab)}\n",
    "    \n",
    "    co_occurrence_matrix = np.zeros((len(vocab), len(vocab)), dtype=np.int)\n",
    "    for (token1, token2), value in tqdm.tqdm(d.items()):\n",
    "        index1 = vocab_index[token1]\n",
    "        index2 = vocab_index[token2]\n",
    "        co_occurrence_matrix[index1, index2] = value\n",
    "        co_occurrence_matrix[index2, index1] = value \n",
    "    print(\"done\")\n",
    "    \n",
    "    #correlation_matrix = np.corrcoef(co_occurrence_matrix)\n",
    "    word_pairs = [(row['First'], row['Last']) for _, row in df_cosine.iterrows()]\n",
    "    correlations = []\n",
    "    for word_pair in tqdm.tqdm(word_pairs):\n",
    "        word1, word2 = word_pair\n",
    "        index1 = vocab_index[word1]\n",
    "        index2 = vocab_index[word2]\n",
    "        correlation = np.corrcoef(co_occurrence_matrix[index1], co_occurrence_matrix[index2])\n",
    "        correlation = correlation[0, 1]\n",
    "        correlations.append(correlation)\n",
    "        \n",
    "    return co_occurrence_matrix, vocab_index, correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d8e3011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 199781/199781 [00:57<00:00, 3446.52it/s]\n",
      "C:\\Users\\berl03\\AppData\\Local\\Temp/ipykernel_20768/2352195706.py:20: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  co_occurrence_matrix = np.zeros((len(vocab), len(vocab)), dtype=np.int)\n",
      "100%|████████████████████████████████████████████████████████████████████| 5440224/5440224 [00:14<00:00, 377920.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 2503203/2503203 [44:50<00:00, 930.25it/s]\n"
     ]
    }
   ],
   "source": [
    "window_size = 3\n",
    "co_occurrence_matrix,vocab_index,correlations = co_occurrence_corr(df_proc[\"text_tok\"].to_list(), window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4015d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cosine[\"corr\"] = correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d921430",
   "metadata": {},
   "outputs": [],
   "source": [
    "frekvence_slov = Counter()\n",
    "for dokument in df_proc[\"text_tok\"].to_list():\n",
    "    frekvence_slov.update(dokument)\n",
    " \n",
    "def ziskej_frekvenci(slovo):\n",
    "    return frekvence_slov.get(slovo, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e27c0ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for index, row in df_cosine.drop_duplicates().iterrows():\n",
    "    word1 = row[\"First\"]\n",
    "    word2 = row[\"Last\"]\n",
    "    index_w1 = vocab_index[word1]\n",
    "    index_w2 = vocab_index[word2]\n",
    "    frequency = co_occurrence_matrix[index_w1, index_w2]\n",
    "    \n",
    "    row_data = {\n",
    "        \"First\": word1,\n",
    "        \"Last\": word2,\n",
    "        \"Frequency\": frequency,\n",
    "        \"frequency_First\":ziskej_frekvenci(word1),\n",
    "        \"frequency_Last\":ziskej_frekvenci(word2),\n",
    "    }\n",
    "    data.append(row_data)\n",
    "res = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3515df65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First</th>\n",
       "      <th>Last</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>frequency_First</th>\n",
       "      <th>frequency_Last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>type</td>\n",
       "      <td>when</td>\n",
       "      <td>17</td>\n",
       "      <td>3401</td>\n",
       "      <td>53246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>type</td>\n",
       "      <td>would</td>\n",
       "      <td>23</td>\n",
       "      <td>3401</td>\n",
       "      <td>53755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>type</td>\n",
       "      <td>followed</td>\n",
       "      <td>0</td>\n",
       "      <td>3401</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>type</td>\n",
       "      <td>she</td>\n",
       "      <td>22</td>\n",
       "      <td>3401</td>\n",
       "      <td>39663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>type</td>\n",
       "      <td>always</td>\n",
       "      <td>9</td>\n",
       "      <td>3401</td>\n",
       "      <td>29915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503198</th>\n",
       "      <td>recipe</td>\n",
       "      <td>saki</td>\n",
       "      <td>0</td>\n",
       "      <td>495</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503199</th>\n",
       "      <td>recipe</td>\n",
       "      <td>intimate</td>\n",
       "      <td>0</td>\n",
       "      <td>495</td>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503200</th>\n",
       "      <td>clayton</td>\n",
       "      <td>saki</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503201</th>\n",
       "      <td>clayton</td>\n",
       "      <td>intimate</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503202</th>\n",
       "      <td>saki</td>\n",
       "      <td>intimate</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2503203 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           First      Last  Frequency  frequency_First  frequency_Last\n",
       "0           type      when         17             3401           53246\n",
       "1           type     would         23             3401           53755\n",
       "2           type  followed          0             3401             815\n",
       "3           type       she         22             3401           39663\n",
       "4           type    always          9             3401           29915\n",
       "...          ...       ...        ...              ...             ...\n",
       "2503198   recipe      saki          0              495              95\n",
       "2503199   recipe  intimate          0              495             895\n",
       "2503200  clayton      saki          0              216              95\n",
       "2503201  clayton  intimate          0              216             895\n",
       "2503202     saki  intimate          0               95             895\n",
       "\n",
       "[2503203 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a10b3ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>first_word</th>\n",
       "      <th>second_word</th>\n",
       "      <th>correlation_of_context</th>\n",
       "      <th>first_second</th>\n",
       "      <th>frequency_co_occurrence</th>\n",
       "      <th>frequency_w1</th>\n",
       "      <th>frequency_w2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300317</td>\n",
       "      <td>type</td>\n",
       "      <td>when</td>\n",
       "      <td>0.512748</td>\n",
       "      <td>type_when</td>\n",
       "      <td>17</td>\n",
       "      <td>3401</td>\n",
       "      <td>53246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.395349</td>\n",
       "      <td>type</td>\n",
       "      <td>would</td>\n",
       "      <td>0.440563</td>\n",
       "      <td>type_would</td>\n",
       "      <td>23</td>\n",
       "      <td>3401</td>\n",
       "      <td>53755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.253379</td>\n",
       "      <td>type</td>\n",
       "      <td>followed</td>\n",
       "      <td>0.503107</td>\n",
       "      <td>type_followed</td>\n",
       "      <td>0</td>\n",
       "      <td>3401</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.204571</td>\n",
       "      <td>type</td>\n",
       "      <td>she</td>\n",
       "      <td>0.511910</td>\n",
       "      <td>type_she</td>\n",
       "      <td>22</td>\n",
       "      <td>3401</td>\n",
       "      <td>39663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.265206</td>\n",
       "      <td>type</td>\n",
       "      <td>always</td>\n",
       "      <td>0.541555</td>\n",
       "      <td>type_always</td>\n",
       "      <td>9</td>\n",
       "      <td>3401</td>\n",
       "      <td>29915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503198</th>\n",
       "      <td>0.421382</td>\n",
       "      <td>recipe</td>\n",
       "      <td>saki</td>\n",
       "      <td>0.738245</td>\n",
       "      <td>recipe_saki</td>\n",
       "      <td>0</td>\n",
       "      <td>495</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503199</th>\n",
       "      <td>0.238683</td>\n",
       "      <td>recipe</td>\n",
       "      <td>intimate</td>\n",
       "      <td>0.685028</td>\n",
       "      <td>recipe_intimate</td>\n",
       "      <td>0</td>\n",
       "      <td>495</td>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503200</th>\n",
       "      <td>0.318745</td>\n",
       "      <td>clayton</td>\n",
       "      <td>saki</td>\n",
       "      <td>0.666173</td>\n",
       "      <td>clayton_saki</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503201</th>\n",
       "      <td>0.334505</td>\n",
       "      <td>clayton</td>\n",
       "      <td>intimate</td>\n",
       "      <td>0.597443</td>\n",
       "      <td>clayton_intimate</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503202</th>\n",
       "      <td>0.262342</td>\n",
       "      <td>saki</td>\n",
       "      <td>intimate</td>\n",
       "      <td>0.728672</td>\n",
       "      <td>saki_intimate</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2503203 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cosine_similarity first_word second_word  correlation_of_context  \\\n",
       "0                 0.300317       type        when                0.512748   \n",
       "1                 0.395349       type       would                0.440563   \n",
       "2                 0.253379       type    followed                0.503107   \n",
       "3                 0.204571       type         she                0.511910   \n",
       "4                 0.265206       type      always                0.541555   \n",
       "...                    ...        ...         ...                     ...   \n",
       "2503198           0.421382     recipe        saki                0.738245   \n",
       "2503199           0.238683     recipe    intimate                0.685028   \n",
       "2503200           0.318745    clayton        saki                0.666173   \n",
       "2503201           0.334505    clayton    intimate                0.597443   \n",
       "2503202           0.262342       saki    intimate                0.728672   \n",
       "\n",
       "             first_second  frequency_co_occurrence  frequency_w1  frequency_w2  \n",
       "0               type_when                       17          3401         53246  \n",
       "1              type_would                       23          3401         53755  \n",
       "2           type_followed                        0          3401           815  \n",
       "3                type_she                       22          3401         39663  \n",
       "4             type_always                        9          3401         29915  \n",
       "...                   ...                      ...           ...           ...  \n",
       "2503198       recipe_saki                        0           495            95  \n",
       "2503199   recipe_intimate                        0           495           895  \n",
       "2503200      clayton_saki                        0           216            95  \n",
       "2503201  clayton_intimate                        0           216           895  \n",
       "2503202     saki_intimate                        0            95           895  \n",
       "\n",
       "[2503203 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"First_Last\"] = res[\"First\"]+\"_\"+res[\"Last\"]\n",
    "df_cosine = df_cosine.drop_duplicates()\n",
    "df_cosine[\"First_Last\"] = df_cosine[\"First\"]+\"_\"+df_cosine[\"Last\"]\n",
    "res = df_cosine.merge(res[[\"First_Last\",\"Frequency\",\"frequency_First\",\"frequency_Last\"]], on=[\"First_Last\"], how = \"inner\").drop_duplicates()\n",
    "res.columns = [\"cosine_similarity\",\"first_word\",\"second_word\",\"correlation_of_context\",\"first_second\",\"frequency_co_occurrence\",\"frequency_w1\",\"frequency_w2\"]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df60b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_word_count = df_proc['text'].apply(len).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51789bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"no_words_corpus\"] = total_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14792520",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"tf_rel_word1\"] = res[\"frequency_w1\"] / res[\"no_words_corpus\"]*100\n",
    "res[\"tf_rel_word2\"] = res[\"frequency_w2\"] / res[\"no_words_corpus\"]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8185328c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>first_word</th>\n",
       "      <th>second_word</th>\n",
       "      <th>correlation_of_context</th>\n",
       "      <th>first_second</th>\n",
       "      <th>frequency_co_occurrence</th>\n",
       "      <th>frequency_w1</th>\n",
       "      <th>frequency_w2</th>\n",
       "      <th>df_word1</th>\n",
       "      <th>no_words_corpus</th>\n",
       "      <th>tf_rel_word1</th>\n",
       "      <th>tf_rel_word2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300317</td>\n",
       "      <td>type</td>\n",
       "      <td>when</td>\n",
       "      <td>0.512748</td>\n",
       "      <td>type_when</td>\n",
       "      <td>17</td>\n",
       "      <td>3401</td>\n",
       "      <td>53246</td>\n",
       "      <td>3401</td>\n",
       "      <td>109853731</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.048470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.395349</td>\n",
       "      <td>type</td>\n",
       "      <td>would</td>\n",
       "      <td>0.440563</td>\n",
       "      <td>type_would</td>\n",
       "      <td>23</td>\n",
       "      <td>3401</td>\n",
       "      <td>53755</td>\n",
       "      <td>3401</td>\n",
       "      <td>109853731</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.048933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.253379</td>\n",
       "      <td>type</td>\n",
       "      <td>followed</td>\n",
       "      <td>0.503107</td>\n",
       "      <td>type_followed</td>\n",
       "      <td>0</td>\n",
       "      <td>3401</td>\n",
       "      <td>815</td>\n",
       "      <td>3401</td>\n",
       "      <td>109853731</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.000742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.204571</td>\n",
       "      <td>type</td>\n",
       "      <td>she</td>\n",
       "      <td>0.511910</td>\n",
       "      <td>type_she</td>\n",
       "      <td>22</td>\n",
       "      <td>3401</td>\n",
       "      <td>39663</td>\n",
       "      <td>3401</td>\n",
       "      <td>109853731</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.036105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.265206</td>\n",
       "      <td>type</td>\n",
       "      <td>always</td>\n",
       "      <td>0.541555</td>\n",
       "      <td>type_always</td>\n",
       "      <td>9</td>\n",
       "      <td>3401</td>\n",
       "      <td>29915</td>\n",
       "      <td>3401</td>\n",
       "      <td>109853731</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.027232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503198</th>\n",
       "      <td>0.421382</td>\n",
       "      <td>recipe</td>\n",
       "      <td>saki</td>\n",
       "      <td>0.738245</td>\n",
       "      <td>recipe_saki</td>\n",
       "      <td>0</td>\n",
       "      <td>495</td>\n",
       "      <td>95</td>\n",
       "      <td>495</td>\n",
       "      <td>109853731</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503199</th>\n",
       "      <td>0.238683</td>\n",
       "      <td>recipe</td>\n",
       "      <td>intimate</td>\n",
       "      <td>0.685028</td>\n",
       "      <td>recipe_intimate</td>\n",
       "      <td>0</td>\n",
       "      <td>495</td>\n",
       "      <td>895</td>\n",
       "      <td>495</td>\n",
       "      <td>109853731</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503200</th>\n",
       "      <td>0.318745</td>\n",
       "      <td>clayton</td>\n",
       "      <td>saki</td>\n",
       "      <td>0.666173</td>\n",
       "      <td>clayton_saki</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>95</td>\n",
       "      <td>216</td>\n",
       "      <td>109853731</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503201</th>\n",
       "      <td>0.334505</td>\n",
       "      <td>clayton</td>\n",
       "      <td>intimate</td>\n",
       "      <td>0.597443</td>\n",
       "      <td>clayton_intimate</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>895</td>\n",
       "      <td>216</td>\n",
       "      <td>109853731</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503202</th>\n",
       "      <td>0.262342</td>\n",
       "      <td>saki</td>\n",
       "      <td>intimate</td>\n",
       "      <td>0.728672</td>\n",
       "      <td>saki_intimate</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>895</td>\n",
       "      <td>95</td>\n",
       "      <td>109853731</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2503203 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cosine_similarity first_word second_word  correlation_of_context  \\\n",
       "0                 0.300317       type        when                0.512748   \n",
       "1                 0.395349       type       would                0.440563   \n",
       "2                 0.253379       type    followed                0.503107   \n",
       "3                 0.204571       type         she                0.511910   \n",
       "4                 0.265206       type      always                0.541555   \n",
       "...                    ...        ...         ...                     ...   \n",
       "2503198           0.421382     recipe        saki                0.738245   \n",
       "2503199           0.238683     recipe    intimate                0.685028   \n",
       "2503200           0.318745    clayton        saki                0.666173   \n",
       "2503201           0.334505    clayton    intimate                0.597443   \n",
       "2503202           0.262342       saki    intimate                0.728672   \n",
       "\n",
       "             first_second  frequency_co_occurrence  frequency_w1  \\\n",
       "0               type_when                       17          3401   \n",
       "1              type_would                       23          3401   \n",
       "2           type_followed                        0          3401   \n",
       "3                type_she                       22          3401   \n",
       "4             type_always                        9          3401   \n",
       "...                   ...                      ...           ...   \n",
       "2503198       recipe_saki                        0           495   \n",
       "2503199   recipe_intimate                        0           495   \n",
       "2503200      clayton_saki                        0           216   \n",
       "2503201  clayton_intimate                        0           216   \n",
       "2503202     saki_intimate                        0            95   \n",
       "\n",
       "         frequency_w2  df_word1  no_words_corpus  tf_rel_word1  tf_rel_word2  \n",
       "0               53246      3401        109853731      0.003096      0.048470  \n",
       "1               53755      3401        109853731      0.003096      0.048933  \n",
       "2                 815      3401        109853731      0.003096      0.000742  \n",
       "3               39663      3401        109853731      0.003096      0.036105  \n",
       "4               29915      3401        109853731      0.003096      0.027232  \n",
       "...               ...       ...              ...           ...           ...  \n",
       "2503198            95       495        109853731      0.000451      0.000086  \n",
       "2503199           895       495        109853731      0.000451      0.000815  \n",
       "2503200            95       216        109853731      0.000197      0.000086  \n",
       "2503201           895       216        109853731      0.000197      0.000815  \n",
       "2503202           895        95        109853731      0.000086      0.000815  \n",
       "\n",
       "[2503203 rows x 12 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d68d4faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>first_word</th>\n",
       "      <th>second_word</th>\n",
       "      <th>correlation_of_context</th>\n",
       "      <th>first_second</th>\n",
       "      <th>frequency_co_occurrence</th>\n",
       "      <th>frequency_w1</th>\n",
       "      <th>frequency_w2</th>\n",
       "      <th>df_word1</th>\n",
       "      <th>no_words_corpus</th>\n",
       "      <th>tf_rel_word1</th>\n",
       "      <th>tf_rel_word2</th>\n",
       "      <th>word1_length</th>\n",
       "      <th>word2_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300317</td>\n",
       "      <td>type</td>\n",
       "      <td>when</td>\n",
       "      <td>0.512748</td>\n",
       "      <td>type_when</td>\n",
       "      <td>17</td>\n",
       "      <td>3401</td>\n",
       "      <td>53246</td>\n",
       "      <td>3401</td>\n",
       "      <td>109853731</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.048470</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.395349</td>\n",
       "      <td>type</td>\n",
       "      <td>would</td>\n",
       "      <td>0.440563</td>\n",
       "      <td>type_would</td>\n",
       "      <td>23</td>\n",
       "      <td>3401</td>\n",
       "      <td>53755</td>\n",
       "      <td>3401</td>\n",
       "      <td>109853731</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.048933</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.253379</td>\n",
       "      <td>type</td>\n",
       "      <td>followed</td>\n",
       "      <td>0.503107</td>\n",
       "      <td>type_followed</td>\n",
       "      <td>0</td>\n",
       "      <td>3401</td>\n",
       "      <td>815</td>\n",
       "      <td>3401</td>\n",
       "      <td>109853731</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.204571</td>\n",
       "      <td>type</td>\n",
       "      <td>she</td>\n",
       "      <td>0.511910</td>\n",
       "      <td>type_she</td>\n",
       "      <td>22</td>\n",
       "      <td>3401</td>\n",
       "      <td>39663</td>\n",
       "      <td>3401</td>\n",
       "      <td>109853731</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.036105</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.265206</td>\n",
       "      <td>type</td>\n",
       "      <td>always</td>\n",
       "      <td>0.541555</td>\n",
       "      <td>type_always</td>\n",
       "      <td>9</td>\n",
       "      <td>3401</td>\n",
       "      <td>29915</td>\n",
       "      <td>3401</td>\n",
       "      <td>109853731</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.027232</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503198</th>\n",
       "      <td>0.421382</td>\n",
       "      <td>recipe</td>\n",
       "      <td>saki</td>\n",
       "      <td>0.738245</td>\n",
       "      <td>recipe_saki</td>\n",
       "      <td>0</td>\n",
       "      <td>495</td>\n",
       "      <td>95</td>\n",
       "      <td>495</td>\n",
       "      <td>109853731</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503199</th>\n",
       "      <td>0.238683</td>\n",
       "      <td>recipe</td>\n",
       "      <td>intimate</td>\n",
       "      <td>0.685028</td>\n",
       "      <td>recipe_intimate</td>\n",
       "      <td>0</td>\n",
       "      <td>495</td>\n",
       "      <td>895</td>\n",
       "      <td>495</td>\n",
       "      <td>109853731</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503200</th>\n",
       "      <td>0.318745</td>\n",
       "      <td>clayton</td>\n",
       "      <td>saki</td>\n",
       "      <td>0.666173</td>\n",
       "      <td>clayton_saki</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>95</td>\n",
       "      <td>216</td>\n",
       "      <td>109853731</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503201</th>\n",
       "      <td>0.334505</td>\n",
       "      <td>clayton</td>\n",
       "      <td>intimate</td>\n",
       "      <td>0.597443</td>\n",
       "      <td>clayton_intimate</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>895</td>\n",
       "      <td>216</td>\n",
       "      <td>109853731</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503202</th>\n",
       "      <td>0.262342</td>\n",
       "      <td>saki</td>\n",
       "      <td>intimate</td>\n",
       "      <td>0.728672</td>\n",
       "      <td>saki_intimate</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>895</td>\n",
       "      <td>95</td>\n",
       "      <td>109853731</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2503203 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cosine_similarity first_word second_word  correlation_of_context  \\\n",
       "0                 0.300317       type        when                0.512748   \n",
       "1                 0.395349       type       would                0.440563   \n",
       "2                 0.253379       type    followed                0.503107   \n",
       "3                 0.204571       type         she                0.511910   \n",
       "4                 0.265206       type      always                0.541555   \n",
       "...                    ...        ...         ...                     ...   \n",
       "2503198           0.421382     recipe        saki                0.738245   \n",
       "2503199           0.238683     recipe    intimate                0.685028   \n",
       "2503200           0.318745    clayton        saki                0.666173   \n",
       "2503201           0.334505    clayton    intimate                0.597443   \n",
       "2503202           0.262342       saki    intimate                0.728672   \n",
       "\n",
       "             first_second  frequency_co_occurrence  frequency_w1  \\\n",
       "0               type_when                       17          3401   \n",
       "1              type_would                       23          3401   \n",
       "2           type_followed                        0          3401   \n",
       "3                type_she                       22          3401   \n",
       "4             type_always                        9          3401   \n",
       "...                   ...                      ...           ...   \n",
       "2503198       recipe_saki                        0           495   \n",
       "2503199   recipe_intimate                        0           495   \n",
       "2503200      clayton_saki                        0           216   \n",
       "2503201  clayton_intimate                        0           216   \n",
       "2503202     saki_intimate                        0            95   \n",
       "\n",
       "         frequency_w2  df_word1  no_words_corpus  tf_rel_word1  tf_rel_word2  \\\n",
       "0               53246      3401        109853731      0.003096      0.048470   \n",
       "1               53755      3401        109853731      0.003096      0.048933   \n",
       "2                 815      3401        109853731      0.003096      0.000742   \n",
       "3               39663      3401        109853731      0.003096      0.036105   \n",
       "4               29915      3401        109853731      0.003096      0.027232   \n",
       "...               ...       ...              ...           ...           ...   \n",
       "2503198            95       495        109853731      0.000451      0.000086   \n",
       "2503199           895       495        109853731      0.000451      0.000815   \n",
       "2503200            95       216        109853731      0.000197      0.000086   \n",
       "2503201           895       216        109853731      0.000197      0.000815   \n",
       "2503202           895        95        109853731      0.000086      0.000815   \n",
       "\n",
       "         word1_length  word2_length  \n",
       "0                   4             4  \n",
       "1                   4             5  \n",
       "2                   4             8  \n",
       "3                   4             3  \n",
       "4                   4             6  \n",
       "...               ...           ...  \n",
       "2503198             6             4  \n",
       "2503199             6             8  \n",
       "2503200             7             4  \n",
       "2503201             7             8  \n",
       "2503202             4             8  \n",
       "\n",
       "[2503203 rows x 14 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['word1_length'] = res['first_word'].apply(len)\n",
    "res['word2_length'] = res['second_word'].apply(len)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312177bb",
   "metadata": {},
   "source": [
    "## Ostatní vlastnosti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2752f628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\berl03\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>first_word</th>\n",
       "      <th>second_word</th>\n",
       "      <th>correlation_of_context</th>\n",
       "      <th>first_second</th>\n",
       "      <th>frequency_co_occurrence</th>\n",
       "      <th>frequency_w1</th>\n",
       "      <th>frequency_w2</th>\n",
       "      <th>df_word1</th>\n",
       "      <th>no_words_corpus</th>\n",
       "      <th>...</th>\n",
       "      <th>word1_length</th>\n",
       "      <th>word2_length</th>\n",
       "      <th>syn_match</th>\n",
       "      <th>syn_match_perc</th>\n",
       "      <th>syn1_count</th>\n",
       "      <th>syn2_count</th>\n",
       "      <th>ant_match</th>\n",
       "      <th>ant_match_perc</th>\n",
       "      <th>ant1_count</th>\n",
       "      <th>ant2_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300317</td>\n",
       "      <td>type</td>\n",
       "      <td>when</td>\n",
       "      <td>0.512748</td>\n",
       "      <td>type_when</td>\n",
       "      <td>17</td>\n",
       "      <td>3401</td>\n",
       "      <td>53246</td>\n",
       "      <td>3401</td>\n",
       "      <td>109853731</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.395349</td>\n",
       "      <td>type</td>\n",
       "      <td>would</td>\n",
       "      <td>0.440563</td>\n",
       "      <td>type_would</td>\n",
       "      <td>23</td>\n",
       "      <td>3401</td>\n",
       "      <td>53755</td>\n",
       "      <td>3401</td>\n",
       "      <td>109853731</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.253379</td>\n",
       "      <td>type</td>\n",
       "      <td>followed</td>\n",
       "      <td>0.503107</td>\n",
       "      <td>type_followed</td>\n",
       "      <td>0</td>\n",
       "      <td>3401</td>\n",
       "      <td>815</td>\n",
       "      <td>3401</td>\n",
       "      <td>109853731</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.204571</td>\n",
       "      <td>type</td>\n",
       "      <td>she</td>\n",
       "      <td>0.511910</td>\n",
       "      <td>type_she</td>\n",
       "      <td>22</td>\n",
       "      <td>3401</td>\n",
       "      <td>39663</td>\n",
       "      <td>3401</td>\n",
       "      <td>109853731</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.265206</td>\n",
       "      <td>type</td>\n",
       "      <td>always</td>\n",
       "      <td>0.541555</td>\n",
       "      <td>type_always</td>\n",
       "      <td>9</td>\n",
       "      <td>3401</td>\n",
       "      <td>29915</td>\n",
       "      <td>3401</td>\n",
       "      <td>109853731</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503198</th>\n",
       "      <td>0.421382</td>\n",
       "      <td>recipe</td>\n",
       "      <td>saki</td>\n",
       "      <td>0.738245</td>\n",
       "      <td>recipe_saki</td>\n",
       "      <td>0</td>\n",
       "      <td>495</td>\n",
       "      <td>95</td>\n",
       "      <td>495</td>\n",
       "      <td>109853731</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503199</th>\n",
       "      <td>0.238683</td>\n",
       "      <td>recipe</td>\n",
       "      <td>intimate</td>\n",
       "      <td>0.685028</td>\n",
       "      <td>recipe_intimate</td>\n",
       "      <td>0</td>\n",
       "      <td>495</td>\n",
       "      <td>895</td>\n",
       "      <td>495</td>\n",
       "      <td>109853731</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503200</th>\n",
       "      <td>0.318745</td>\n",
       "      <td>clayton</td>\n",
       "      <td>saki</td>\n",
       "      <td>0.666173</td>\n",
       "      <td>clayton_saki</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>95</td>\n",
       "      <td>216</td>\n",
       "      <td>109853731</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503201</th>\n",
       "      <td>0.334505</td>\n",
       "      <td>clayton</td>\n",
       "      <td>intimate</td>\n",
       "      <td>0.597443</td>\n",
       "      <td>clayton_intimate</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>895</td>\n",
       "      <td>216</td>\n",
       "      <td>109853731</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503202</th>\n",
       "      <td>0.262342</td>\n",
       "      <td>saki</td>\n",
       "      <td>intimate</td>\n",
       "      <td>0.728672</td>\n",
       "      <td>saki_intimate</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>895</td>\n",
       "      <td>95</td>\n",
       "      <td>109853731</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2503203 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cosine_similarity first_word second_word  correlation_of_context  \\\n",
       "0                 0.300317       type        when                0.512748   \n",
       "1                 0.395349       type       would                0.440563   \n",
       "2                 0.253379       type    followed                0.503107   \n",
       "3                 0.204571       type         she                0.511910   \n",
       "4                 0.265206       type      always                0.541555   \n",
       "...                    ...        ...         ...                     ...   \n",
       "2503198           0.421382     recipe        saki                0.738245   \n",
       "2503199           0.238683     recipe    intimate                0.685028   \n",
       "2503200           0.318745    clayton        saki                0.666173   \n",
       "2503201           0.334505    clayton    intimate                0.597443   \n",
       "2503202           0.262342       saki    intimate                0.728672   \n",
       "\n",
       "             first_second  frequency_co_occurrence  frequency_w1  \\\n",
       "0               type_when                       17          3401   \n",
       "1              type_would                       23          3401   \n",
       "2           type_followed                        0          3401   \n",
       "3                type_she                       22          3401   \n",
       "4             type_always                        9          3401   \n",
       "...                   ...                      ...           ...   \n",
       "2503198       recipe_saki                        0           495   \n",
       "2503199   recipe_intimate                        0           495   \n",
       "2503200      clayton_saki                        0           216   \n",
       "2503201  clayton_intimate                        0           216   \n",
       "2503202     saki_intimate                        0            95   \n",
       "\n",
       "         frequency_w2  df_word1  no_words_corpus  ...  word1_length  \\\n",
       "0               53246      3401        109853731  ...             4   \n",
       "1               53755      3401        109853731  ...             4   \n",
       "2                 815      3401        109853731  ...             4   \n",
       "3               39663      3401        109853731  ...             4   \n",
       "4               29915      3401        109853731  ...             4   \n",
       "...               ...       ...              ...  ...           ...   \n",
       "2503198            95       495        109853731  ...             6   \n",
       "2503199           895       495        109853731  ...             6   \n",
       "2503200            95       216        109853731  ...             7   \n",
       "2503201           895       216        109853731  ...             7   \n",
       "2503202           895        95        109853731  ...             4   \n",
       "\n",
       "         word2_length  syn_match  syn_match_perc  syn1_count  syn2_count  \\\n",
       "0                   4          0             0.0           6           0   \n",
       "1                   5          0             0.0           6           0   \n",
       "2                   8          0             0.0           6          28   \n",
       "3                   3          0             0.0           6           0   \n",
       "4                   6          0             0.0           6           8   \n",
       "...               ...        ...             ...         ...         ...   \n",
       "2503198             4          0             0.0           2           7   \n",
       "2503199             8          0             0.0           2          13   \n",
       "2503200             4          0             0.0           0           7   \n",
       "2503201             8          0             0.0           0          13   \n",
       "2503202             8          0             0.0           7          13   \n",
       "\n",
       "         ant_match  ant_match_perc  ant1_count  ant2_count  \n",
       "0                0             0.0           1           0  \n",
       "1                0             0.0           1           0  \n",
       "2                0             0.0           1           2  \n",
       "3                0             0.0           1           0  \n",
       "4                0             0.0           1           1  \n",
       "...            ...             ...         ...         ...  \n",
       "2503198          0             0.0           0           0  \n",
       "2503199          0             0.0           0           0  \n",
       "2503200          0             0.0           0           0  \n",
       "2503201          0             0.0           0           0  \n",
       "2503202          0             0.0           0           0  \n",
       "\n",
       "[2503203 rows x 22 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "\n",
    "# Získání synonym a antonym pro každé slovo v sloupcích word1 a word2\n",
    "def get_synonyms_antonyms(word):\n",
    "    synonyms = set()\n",
    "    antonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "            if lemma.antonyms():\n",
    "                antonyms.add(lemma.antonyms()[0].name())\n",
    "    return synonyms, antonyms\n",
    "\n",
    "# kolik synonym je spolecnych pro obe slova\n",
    "def find_synonym_match(word1, word2):\n",
    "    syn1, _ = get_synonyms_antonyms(word1)\n",
    "    syn2, _ = get_synonyms_antonyms(word2)\n",
    "    intersection_count = len(syn1.intersection(syn2))\n",
    "    return intersection_count, (intersection_count / max(len(syn1), len(syn2))) if max(len(syn1), len(syn2)) != 0 else 0, len(syn1), len(syn2)\n",
    "\n",
    "# kolik antonym je spolecnych pro obe slova\n",
    "def find_antonym_match(word1, word2):\n",
    "    _, ant1 = get_synonyms_antonyms(word1)\n",
    "    _, ant2 = get_synonyms_antonyms(word2)\n",
    "    intersection_count = len(ant1.intersection(ant2))\n",
    "    return intersection_count, (intersection_count / max(len(ant1), len(ant2))) if max(len(ant1), len(ant2)) != 0 else 0, len(ant1), len(ant2)\n",
    "\n",
    "res['syn_match'], res['syn_match_perc'], res['syn1_count'], res['syn2_count'] = zip(*res.apply(lambda row: find_synonym_match(row['first_word'], row['second_word']), axis=1))\n",
    "res['ant_match'], res['ant_match_perc'], res['ant1_count'], res['ant2_count'] = zip(*res.apply(lambda row: find_antonym_match(row['first_word'], row['second_word']), axis=1))\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf29efc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = res.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26ca98ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Získání morfo-syntaktických vlastností (POS tags) pro každé slovo v sloupcích word1 a word2 pomocí SpaCy\n",
    "def get_pos_tags(word):\n",
    "    doc = nlp(word)\n",
    "    return [token.pos_ for token in doc]\n",
    "\n",
    "df['word1_pos_tags'] = df['first_word'].apply(get_pos_tags)\n",
    "df['word2_pos_tags'] = df['second_word'].apply(get_pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11259b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>first_word</th>\n",
       "      <th>second_word</th>\n",
       "      <th>correlation_of_context</th>\n",
       "      <th>first_second</th>\n",
       "      <th>frequency_co_occurrence</th>\n",
       "      <th>frequency_w1</th>\n",
       "      <th>frequency_w2</th>\n",
       "      <th>df_word1</th>\n",
       "      <th>no_words_corpus</th>\n",
       "      <th>...</th>\n",
       "      <th>syn1_count</th>\n",
       "      <th>syn2_count</th>\n",
       "      <th>ant_match</th>\n",
       "      <th>ant_match_perc</th>\n",
       "      <th>ant1_count</th>\n",
       "      <th>ant2_count</th>\n",
       "      <th>word1_pos_tags</th>\n",
       "      <th>word2_pos_tags</th>\n",
       "      <th>is_stop_word1</th>\n",
       "      <th>is_stop_word2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300317</td>\n",
       "      <td>type</td>\n",
       "      <td>when</td>\n",
       "      <td>0.512748</td>\n",
       "      <td>type_when</td>\n",
       "      <td>17</td>\n",
       "      <td>3401</td>\n",
       "      <td>53246</td>\n",
       "      <td>3401</td>\n",
       "      <td>109853731</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[NOUN]</td>\n",
       "      <td>[SCONJ]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.395349</td>\n",
       "      <td>type</td>\n",
       "      <td>would</td>\n",
       "      <td>0.440563</td>\n",
       "      <td>type_would</td>\n",
       "      <td>23</td>\n",
       "      <td>3401</td>\n",
       "      <td>53755</td>\n",
       "      <td>3401</td>\n",
       "      <td>109853731</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[NOUN]</td>\n",
       "      <td>[AUX]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.253379</td>\n",
       "      <td>type</td>\n",
       "      <td>followed</td>\n",
       "      <td>0.503107</td>\n",
       "      <td>type_followed</td>\n",
       "      <td>0</td>\n",
       "      <td>3401</td>\n",
       "      <td>815</td>\n",
       "      <td>3401</td>\n",
       "      <td>109853731</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[NOUN]</td>\n",
       "      <td>[VERB]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.204571</td>\n",
       "      <td>type</td>\n",
       "      <td>she</td>\n",
       "      <td>0.511910</td>\n",
       "      <td>type_she</td>\n",
       "      <td>22</td>\n",
       "      <td>3401</td>\n",
       "      <td>39663</td>\n",
       "      <td>3401</td>\n",
       "      <td>109853731</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[NOUN]</td>\n",
       "      <td>[PRON]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.265206</td>\n",
       "      <td>type</td>\n",
       "      <td>always</td>\n",
       "      <td>0.541555</td>\n",
       "      <td>type_always</td>\n",
       "      <td>9</td>\n",
       "      <td>3401</td>\n",
       "      <td>29915</td>\n",
       "      <td>3401</td>\n",
       "      <td>109853731</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[NOUN]</td>\n",
       "      <td>[ADV]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503198</th>\n",
       "      <td>0.421382</td>\n",
       "      <td>recipe</td>\n",
       "      <td>saki</td>\n",
       "      <td>0.738245</td>\n",
       "      <td>recipe_saki</td>\n",
       "      <td>0</td>\n",
       "      <td>495</td>\n",
       "      <td>95</td>\n",
       "      <td>495</td>\n",
       "      <td>109853731</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[NOUN]</td>\n",
       "      <td>[VERB]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503199</th>\n",
       "      <td>0.238683</td>\n",
       "      <td>recipe</td>\n",
       "      <td>intimate</td>\n",
       "      <td>0.685028</td>\n",
       "      <td>recipe_intimate</td>\n",
       "      <td>0</td>\n",
       "      <td>495</td>\n",
       "      <td>895</td>\n",
       "      <td>495</td>\n",
       "      <td>109853731</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[NOUN]</td>\n",
       "      <td>[VERB]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503200</th>\n",
       "      <td>0.318745</td>\n",
       "      <td>clayton</td>\n",
       "      <td>saki</td>\n",
       "      <td>0.666173</td>\n",
       "      <td>clayton_saki</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>95</td>\n",
       "      <td>216</td>\n",
       "      <td>109853731</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[PROPN]</td>\n",
       "      <td>[VERB]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503201</th>\n",
       "      <td>0.334505</td>\n",
       "      <td>clayton</td>\n",
       "      <td>intimate</td>\n",
       "      <td>0.597443</td>\n",
       "      <td>clayton_intimate</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>895</td>\n",
       "      <td>216</td>\n",
       "      <td>109853731</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[PROPN]</td>\n",
       "      <td>[VERB]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503202</th>\n",
       "      <td>0.262342</td>\n",
       "      <td>saki</td>\n",
       "      <td>intimate</td>\n",
       "      <td>0.728672</td>\n",
       "      <td>saki_intimate</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>895</td>\n",
       "      <td>95</td>\n",
       "      <td>109853731</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[VERB]</td>\n",
       "      <td>[VERB]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2503203 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cosine_similarity first_word second_word  correlation_of_context  \\\n",
       "0                 0.300317       type        when                0.512748   \n",
       "1                 0.395349       type       would                0.440563   \n",
       "2                 0.253379       type    followed                0.503107   \n",
       "3                 0.204571       type         she                0.511910   \n",
       "4                 0.265206       type      always                0.541555   \n",
       "...                    ...        ...         ...                     ...   \n",
       "2503198           0.421382     recipe        saki                0.738245   \n",
       "2503199           0.238683     recipe    intimate                0.685028   \n",
       "2503200           0.318745    clayton        saki                0.666173   \n",
       "2503201           0.334505    clayton    intimate                0.597443   \n",
       "2503202           0.262342       saki    intimate                0.728672   \n",
       "\n",
       "             first_second  frequency_co_occurrence  frequency_w1  \\\n",
       "0               type_when                       17          3401   \n",
       "1              type_would                       23          3401   \n",
       "2           type_followed                        0          3401   \n",
       "3                type_she                       22          3401   \n",
       "4             type_always                        9          3401   \n",
       "...                   ...                      ...           ...   \n",
       "2503198       recipe_saki                        0           495   \n",
       "2503199   recipe_intimate                        0           495   \n",
       "2503200      clayton_saki                        0           216   \n",
       "2503201  clayton_intimate                        0           216   \n",
       "2503202     saki_intimate                        0            95   \n",
       "\n",
       "         frequency_w2  df_word1  no_words_corpus  ...  syn1_count  syn2_count  \\\n",
       "0               53246      3401        109853731  ...           6           0   \n",
       "1               53755      3401        109853731  ...           6           0   \n",
       "2                 815      3401        109853731  ...           6          28   \n",
       "3               39663      3401        109853731  ...           6           0   \n",
       "4               29915      3401        109853731  ...           6           8   \n",
       "...               ...       ...              ...  ...         ...         ...   \n",
       "2503198            95       495        109853731  ...           2           7   \n",
       "2503199           895       495        109853731  ...           2          13   \n",
       "2503200            95       216        109853731  ...           0           7   \n",
       "2503201           895       216        109853731  ...           0          13   \n",
       "2503202           895        95        109853731  ...           7          13   \n",
       "\n",
       "         ant_match  ant_match_perc  ant1_count  ant2_count  word1_pos_tags  \\\n",
       "0                0             0.0           1           0          [NOUN]   \n",
       "1                0             0.0           1           0          [NOUN]   \n",
       "2                0             0.0           1           2          [NOUN]   \n",
       "3                0             0.0           1           0          [NOUN]   \n",
       "4                0             0.0           1           1          [NOUN]   \n",
       "...            ...             ...         ...         ...             ...   \n",
       "2503198          0             0.0           0           0          [NOUN]   \n",
       "2503199          0             0.0           0           0          [NOUN]   \n",
       "2503200          0             0.0           0           0         [PROPN]   \n",
       "2503201          0             0.0           0           0         [PROPN]   \n",
       "2503202          0             0.0           0           0          [VERB]   \n",
       "\n",
       "         word2_pos_tags  is_stop_word1  is_stop_word2  \n",
       "0               [SCONJ]              0              1  \n",
       "1                 [AUX]              0              1  \n",
       "2                [VERB]              0              0  \n",
       "3                [PRON]              0              1  \n",
       "4                 [ADV]              0              1  \n",
       "...                 ...            ...            ...  \n",
       "2503198          [VERB]              0              0  \n",
       "2503199          [VERB]              0              0  \n",
       "2503200          [VERB]              0              0  \n",
       "2503201          [VERB]              0              0  \n",
       "2503202          [VERB]              0              0  \n",
       "\n",
       "[2503203 rows x 26 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "def is_stop_word(word):\n",
    "    return word in stop_words\n",
    "df['is_stop_word1'] = df['first_word'].apply(is_stop_word).astype(int)\n",
    "df['is_stop_word2'] = df['second_word'].apply(is_stop_word).astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15875e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pos_tag_eq\"] = df[\"word1_pos_tags\"] == df[\"word2_pos_tags\"]\n",
    "df[\"pos_tag_eq\"] = df[\"pos_tag_eq\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2493694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df_prep_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f253ea46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
